# DiffusionVideoEditing
Official project repo for paper "Speech Driven Video Editing via an Audio-Conditioned Diffusion Model" 

Shoutout to https://github.com/Janspiry/Palette-Image-to-Image-Diffusion-Models ! Most of the code in this repo is taken from there. It's a really good implementation of the Palette image2image paper, so go check it out! 

You can check out some of the results on the project page found here: https://danbigioi.github.io/DiffusionVideoEditing/

And if you want to read the paper, this is the link to the arxiv submission: https://arxiv.org/abs/2301.04474 

# UPDATE: 

Hey all! Finally finished the paper, and submitted a much improved version of it to a conference. In the meanwhile I've uploaded the revised paper to Arxiv, and should be available in the next couple of days. I'm currently updating this repo with trained model weights, code, preprocessing scripts, and everything you could need to replicate and improve the results. Will be finished by this Friday the 12th by the latest! 
